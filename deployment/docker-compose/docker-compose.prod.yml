# Production Docker Compose for deployment
services:
  web-scraper:
    image: web-scraper:${VERSION:-latest}
    container_name: web-scraper-prod
    environment:
      - PYTHONPATH=/app
      - LOG_LEVEL=${LOG_LEVEL:-WARNING}
      - SCRAPER_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
    volumes:
      # Only mount data directories in production
      - ../../storage:/app/storage
      - scraper-logs:/app/logs
    restart: always
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "python", "-c", "from src.core.logger import get_logger; get_logger('health')"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s
    networks:
      - scraper-network

  # Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: web-scraper-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../config/ssl:/etc/nginx/ssl:ro
    depends_on:
      - web-scraper
    restart: always
    networks:
      - scraper-network

volumes:
  scraper-logs:
    driver: local

networks:
  scraper-network:
    driver: bridge