apiVersion: batch/v1
kind: Job
metadata:
  name: scraper-batch-template
  namespace: web-scraper-python
  labels:
    app: web-scraper-python
    component: batch-job
    managed-by: orchestrator
spec:
  # Job lifecycle configuration
  ttlSecondsAfterFinished: 300  # 5 minutes cleanup
  activeDeadlineSeconds: 600    # 10 minutes timeout
  backoffLimit: 2               # Maximum retries
  
  template:
    metadata:
      labels:
        app: web-scraper-python
        component: batch-job
      annotations:
        sidecar.istio.io/inject: "false"  # Disable service mesh for batch jobs
    spec:
      restartPolicy: Never
      
      # Security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
        seccompProfile:
          type: RuntimeDefault
      
      containers:
        - name: scraper
          image: universal-web-scraper-python:latest
          imagePullPolicy: IfNotPresent
          
          # Command will be overridden by orchestrator
          command: ['python', '-m', 'src.main']
          args:
            - '--parser=generic_news'
            - '--urls=https://example.com'
            - '--max-concurrency=2'
            - '--batch-mode'
          
          env:
            # Python configuration
            - name: PYTHONUNBUFFERED
              value: "1"
            - name: PYTHONDONTWRITEBYTECODE
              value: "1"
            - name: PYTHONPATH
              value: "/app"
            
            # Application configuration
            - name: LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: web-scraper-python-config
                  key: LOG_LEVEL
            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: web-scraper-python-config
                  key: NODE_ENV
            - name: MAX_CONCURRENT_REQUESTS
              valueFrom:
                configMapKeyRef:
                  name: web-scraper-python-config
                  key: MAX_CONCURRENT_REQUESTS
                  
            # Playwright configuration
            - name: PLAYWRIGHT_BROWSERS_PATH
              value: "/app/.cache/ms-playwright"
            
            # Job metadata (set by orchestrator)
            - name: BATCH_ID
              value: "0"
            - name: JOB_ID
              value: "template"
          
          resources:
            requests:
              memory: '512Mi'
              cpu: '200m'
              ephemeral-storage: '1Gi'
            limits:
              memory: '1Gi'
              cpu: '800m'
              ephemeral-storage: '2Gi'
          
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL
          
          volumeMounts:
            # Writable directories
            - name: tmp
              mountPath: /tmp
            - name: cache
              mountPath: /app/.cache
            - name: playwright-cache
              mountPath: /app/.cache/ms-playwright
            
            # Optional: Seed files
            - name: seed-files
              mountPath: /app/seeds
              readOnly: true
          
          # Health checks for monitoring
          livenessProbe:
            exec:
              command:
                - python
                - -c
                - "import sys; sys.exit(0)"
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3
      
      volumes:
        # Temporary storage
        - name: tmp
          emptyDir:
            sizeLimit: 100Mi
        
        # Cache directories
        - name: cache
          emptyDir:
            sizeLimit: 500Mi
        - name: playwright-cache
          emptyDir:
            sizeLimit: 1Gi
        
        # Seed files (optional ConfigMap)
        - name: seed-files
          configMap:
            name: scraper-seeds
            optional: true
      
      # Node affinity for resource optimization
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              preference:
                matchExpressions:
                  - key: node-type
                    operator: In
                    values: ["compute", "worker"]
        
        # Spread batch jobs across nodes
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 50
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    component: batch-job
                topologyKey: kubernetes.io/hostname
      
      # Tolerations for dedicated batch nodes
      tolerations:
        - key: "batch-workload"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      
      terminationGracePeriodSeconds: 30
